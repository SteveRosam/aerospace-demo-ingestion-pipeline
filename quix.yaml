# Quix Project Descriptor
# This file describes the data pipeline and configuration of resources of a Quix Project.

metadata:
  version: 1.0

# This section describes the Deployments of the data pipeline
deployments:
  - name: Test Rig Data
    application: test-rig-data
    version: latest
    deploymentType: Service
    resources:
      cpu: 200
      memory: 500
      replicas: 1
    publicAccess:
      enabled: true
      urlPrefix: gateway
    variables:
      - name: output
        inputType: OutputTopic
        description: This is the output topic for hello world data
        required: true
        value: edf-data
  - name: Data Prepper
    application: data-prepper
    version: latest
    deploymentType: Service
    resources:
      cpu: 200
      memory: 500
      replicas: 1
    variables:
      - name: DATA_TOPIC
        inputType: InputTopic
        description: Name of the ingress data topic.
        value: normalised-data
      - name: CONFIG_TOPIC
        inputType: InputTopic
        description: Name of the ingress config topic.
        value: config-updates
      - name: OUTPUT_TOPIC
        inputType: OutputTopic
        description: Name of the output topic to write enriched data to.
        value: prepped-data
      - name: CONSUMER_GROUP
        inputType: FreeText
        description: Consumer group name.
        required: true
        value: data-prepper
  - name: Data normalisation
    application: data-normalisation
    version: latest
    deploymentType: Service
    resources:
      cpu: 200
      memory: 500
      replicas: 1
    variables:
      - name: input
        inputType: InputTopic
        description: Name of the input topic to listen to.
        value: edf-data
      - name: output
        inputType: OutputTopic
        description: Name of the output topic to write to.
        value: normalised-data
  - name: Quix TS Datalake Sink
    image: quixcontainerregistry.azurecr.io/quix-datalake-ts-sink:20250917.1-auth
    deploymentType: Service
    resources:
      cpu: 200
      memory: 500
      replicas: 1
    variables:
      - name: input
        inputType: InputTopic
        description: Name of the Kafka input topic to consume from
        required: true
        value: prepped_data
      - name: S3_BUCKET
        inputType: FreeText
        description: S3 bucket name for storing Parquet files
        required: true
        value: quix-bucket
      - name: S3_PREFIX
        inputType: FreeText
        description: S3 prefix/path for data files
        value: quixlake
      - name: TABLE_NAME
        inputType: FreeText
        description: Table name for data organization and registration
        value: cpu-metrics
      - name: HIVE_COLUMNS
        inputType: FreeText
        description: Comma-separated list of columns for Hive partitioning. Include year/month/day/hour to extract from TIMESTAMP_COLUMN (e.g., location,year,month,day,sensor_type)
        value: campaign_id,environment_id,test_id
      - name: TIMESTAMP_COLUMN
        inputType: FreeText
        description: Column containing timestamp values to extract year/month/day/hour from
        value: timestamp
      - name: CATALOG_URL
        inputType: FreeText
        description: REST Catalog URL for optional table registration (leave empty to skip)
        value: http://iceberg-catalog
      - name: CATALOG_AUTH_TOKEN
        inputType: Secret
        description: auth token for catalog
        secretKey: sdk_token
      - name: AUTO_DISCOVER
        inputType: FreeText
        description: Automatically register table in REST Catalog on first write
        value: true
      - name: CATALOG_NAMESPACE
        inputType: FreeText
        description: Catalog namespace for table registration
        value: default
      - name: BATCH_SIZE
        inputType: FreeText
        description: Number of messages to batch before writing to S3
        value: 1000
      - name: COMMIT_INTERVAL
        inputType: FreeText
        description: Kafka commit interval in seconds
        value: 30
      - name: CONSUMER_GROUP
        inputType: FreeText
        description: Kafka consumer group name
        value: aws_sink
      - name: AUTO_OFFSET_RESET
        inputType: FreeText
        description: Where to start consuming if no offset exists
        value: earliest
      - name: AWS_ACCESS_KEY_ID
        inputType: Secret
        description: AWS Access Key ID for S3 access
        secretKey: aws_access_key
      - name: AWS_SECRET_ACCESS_KEY
        inputType: Secret
        description: AWS Secret Access Key for S3 access
        secretKey: aws_secret_key
      - name: AWS_REGION
        inputType: FreeText
        description: AWS region for S3 bucket
        value: us-west-2


# This section describes the Topics of the data pipeline
topics:
  - name: http-source
  - name: edf-data
  - name: config-updates
    linkedTopic:
      workspaceId: quixers-testmanagerdemo-dev
  - name: prepped-data
  - name: transform
  - name: normalised-data
